<!--This file created 7/2/97 10:05 AM by Claris Home Page version 2.0-->
<HTML>
<HEAD>
   <TITLE>96 Self Assessment</TITLE>
   <META NAME=GENERATOR CONTENT="Claris Home Page 2.0">
   <X-SAS-WINDOW TOP=114 BOTTOM=624 LEFT=16 RIGHT=546>
</HEAD>
<BODY BGCOLOR="#FFFFFF">

<H1>Self Assessment</H1>

<P>Assess your answer to <A HREF="ques96.html">the programming
question</A> using the following critiques. Figure approximately 2
points for each serious class of failure. The question as a whole was
worth 10 points. <A HREF="ans96.lisp">The sample answer</A> is
probably worth 20, since it's beyond what I could do in an hour.</P>

<H2>Incorrect Singularity Assumptions</H2>

<P>One of the main points of this question was dealing with several
many-to-many relationships. Words and phrases can have multiple
meanings, target concepts can have multiple index sets, the same
concepts may appear in the input multiple times, and so on.</P>

<P>Subtract points if your code assumes only one</P>

<UL>
   <LI>word per concept, no multiword phrases
   
   <LI>word sense (concept) per input word or phrase
   
   <LI>index set for each target concept
   
   <LI>target concept for each index set
</UL>

<P>Extra credit if you noted that ambiguous inputs might better be
done by separately scoring each parse, rather than simply lumping all
word and phrase concepts together.</P>

<H2>Egregious Inefficiencies</H2>

<P>The question explicitly said not to trade clarity for efficiency,
but some inefficiencies were unnecessary and no clearer than more
efficient alternatives.</P>

<P>Subtract points if your code</P>

<UL>
   <LI>builds <EM>lists</EM> for the three sets <STRONG><EM>p+s</EM>
   </STRONG>, <STRONG><EM>p-s</EM> </STRONG>, and
   <STRONG><EM>s-p</EM> </STRONG>; all you need to do is to count
   
   <LI>computes the three sets using <EM>three</EM> scans over the
   sets; only two scans are needed, once over
   <STRONG><EM>S</EM></STRONG> and once over
   <STRONG><EM>P</EM></STRONG>; the third value can be calculated by
   simple subtraction
   
   <LI>computes the three sets using <EM>one</EM> scan over one of
   the two sets; you can't calculate <STRONG><EM>p-s</EM> </STRONG>,
   for example, if you've only scanned <STRONG><EM>S</EM></STRONG>
</UL>

<H2>No Hope for the Future</H2>

<P>The other main point of the question was to see if you had some
idea for seriously improving the efficiency of the method so that it
would scale to large memories. Set operations like intersection are
N-squared. Simply speeding up the operations, e.g., by using caching,
isn't enough. You have to remove the N-squared factor, or drastically
control N.</P>

<P><A HREF="program-ans.lisp">The example solution</A> points to a
common approach -- building a discrimination tree of index sets.
There are also methods for reducing the code of set operations from N
times M to N plus M.</P>

<P>Subtract points if you had no suggestions for improving the code
beyond caching or replacing list building with counting.</P>

<H2>Miscellaneous</H2>

<P>Subtract points if your code</P>

<UL>
   <LI>scores and sorts all index sets without first making sure an
   index set is <EM>relevant</EM>, i.e., has at least one concept in
   <STRONG><EM>p+s</EM> </STRONG>; since <STRONG><EM>p-s</EM>
   </STRONG>, and <STRONG><EM>s-p</EM> </STRONG> subtract from the
   index set's score, many obvious formulae for
   <CODE>score-match</CODE> may generate higher scores for irrelevant
   index sets with only a few elements, than for relevant index sets
   with many elements
</UL>

<P>
<HR>
</P>
</BODY>
</HTML>
